#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê°•í™”ëœ Unit ë°ì´í„° ê²€ì¦ ë„êµ¬
- ê¸°ë³¸ JSON ê²€ì¦
- í•œê¸€-ì˜ì–´ ì˜ë¯¸ ì¼ì¹˜ì„± ê²€ì¦
- í’ˆì‚¬ ì¼ì¹˜ì„± ê²€ì¦
- íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ê²€ì¦
"""

import json
import re
import sys
import os

def validate_basic_structure(data):
    """ê¸°ë³¸ JSON êµ¬ì¡° ê²€ì¦"""
    errors = []
    
    for i, word in enumerate(data):
        # í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸
        if 'ko' not in word or 'en' not in word or 'pos' not in word:
            errors.append(f"Line {i+1}: í•„ìˆ˜ í•„ë“œ ëˆ„ë½ (ko, en, pos)")
            continue
        
        # ë¹ˆ ê°’ í™•ì¸
        if not word['ko'].strip() or not word['en'].strip() or not word['pos'].strip():
            errors.append(f"Line {i+1}: ë¹ˆ ê°’ ë°œê²¬")
        
        # ì˜ë¬¸ ë‹¨ì–´ í˜•ì‹ ê²€ì¦ (í’ˆì‚¬ í‘œì‹œ í—ˆìš©)
        if not re.match(r'^[a-zA-Z\s\-\'().]+$', word['en']):
            errors.append(f"Line {i+1}: ì˜ë¬¸ ë‹¨ì–´ í˜•ì‹ ì˜¤ë¥˜: {word['en']}")
        
        # í•œê¸€ ë‹¨ì–´ í˜•ì‹ ê²€ì¦
        if not re.match(r'^[ê°€-í£a-zA-Z0-9\s,()!]+$', word['ko']):
            errors.append(f"Line {i+1}: í•œê¸€ ë‹¨ì–´ í˜•ì‹ ì˜¤ë¥˜: {word['ko']}")
        
        # í’ˆì‚¬ í˜•ì‹ ê²€ì¦
        valid_pos = ['n.', 'v.', 'adj.', 'adv.', 'prep.', 'conj.', 'interj.', 'int.', 'phr.', 'pron.', 'past', 's', 'ing', 'to inf.']
        pos_valid = any(word['pos'].startswith(p) for p in valid_pos)
        if not pos_valid:
            errors.append(f"Line {i+1}: í’ˆì‚¬ í˜•ì‹ ì˜¤ë¥˜: {word['pos']}")
    
    return errors

def validate_word_meaning_consistency(data):
    """í•œê¸€-ì˜ì–´ ì˜ë¯¸ ì¼ì¹˜ì„± ê²€ì¦"""
    errors = []
    
    # íŠ¹ì • ë‹¨ì–´ë“¤ì˜ ì˜ë¯¸ ê²€ì¦
    meaning_checks = {
        'puddle': ['ë¬¼ì›…ë©ì´', 'ì›…ë©ì´', 'ë¬¼ê³ ì¸ ê³³'],
        'darn it': ['ì  ì¥', 'ì´ëŸ°', 'ì•„'],
        'assignment': ['ê³¼ì œ', 'ì„ë¬´', 'ìˆ™ì œ'],
        'task': ['ì„ë¬´', 'ê³¼ì œ', 'ì‘ì—…'],
        'writing': ['ì“°ê¸°', 'ê¸€ì“°ê¸°', 'ì‘ë¬¸'],
        'soldier': ['êµ°ì¸', 'ë³‘ì‚¬', 'ì „ì‚¬'],
        'art': ['ë¯¸ìˆ ', 'ì˜ˆìˆ ', 'ì•„íŠ¸'],
        'elevator': ['ìŠ¹ê°•ê¸°', 'ì—˜ë¦¬ë² ì´í„°'],
        'restroom': ['í™”ì¥ì‹¤', 'ì„¸ë©´ì‹¤', 'í™”ì¥ì‹¤'],
        'weather': ['ë‚ ì”¨', 'ê¸°ìƒ'],
        'lunch': ['ì ì‹¬', 'ì ì‹¬ì‹ì‚¬'],
        'earth': ['ì§€êµ¬', 'í™', 'ë•…'],
        'street': ['ê±°ë¦¬', 'ë„ë¡œ', 'ê¸¸']
    }
    
    for i, word in enumerate(data):
        en_word = word['en'].lower().strip()
        ko_word = word['ko'].strip()
        
        if en_word in meaning_checks:
            valid_meanings = meaning_checks[en_word]
            if not any(valid in ko_word for valid in valid_meanings):
                errors.append(f"Line {i+1}: '{en_word}'ì˜ í•œê¸€ ëœ» '{ko_word}'ê°€ ë¶€ì ì ˆí•¨. ì˜¬ë°”ë¥¸ ëœ»: {valid_meanings}")
    
    return errors

def validate_pos_consistency(data):
    """í’ˆì‚¬ ì¼ì¹˜ì„± ê²€ì¦"""
    errors = []
    
    # ê°íƒ„ì‚¬ ë‹¨ì–´ë“¤
    interjection_words = ['darn it', 'oh no', 'wow', 'oh my', 'gee', 'gosh']
    
    for i, word in enumerate(data):
        en_word = word['en'].lower().strip()
        pos = word['pos'].strip()
        
        # ê°íƒ„ì‚¬ ë‹¨ì–´ ê²€ì¦
        if en_word in interjection_words:
            if 'int.' not in pos and 'interj.' not in pos:
                errors.append(f"Line {i+1}: '{en_word}'ëŠ” ê°íƒ„ì‚¬ì¸ë° í’ˆì‚¬ê°€ '{pos}'ë¡œ í‘œê¸°ë¨")
        
        # ëª…ì‚¬ ë‹¨ì–´ ê²€ì¦
        if en_word in ['puddle', 'assignment', 'task', 'writing', 'soldier', 'art', 'elevator', 'restroom', 'weather', 'lunch', 'earth', 'street']:
            if 'n.' not in pos:
                errors.append(f"Line {i+1}: '{en_word}'ëŠ” ëª…ì‚¬ì¸ë° í’ˆì‚¬ê°€ '{pos}'ë¡œ í‘œê¸°ë¨")
    
    return errors

def validate_special_cases(data):
    """íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ê²€ì¦"""
    errors = []
    
    for i, word in enumerate(data):
        en_word = word['en'].strip()
        ko_word = word['ko'].strip()
        
        # puddle íŠ¹ë³„ ê²€ì¦
        if en_word == 'puddle':
            if ko_word not in ['ë¬¼ì›…ë©ì´', 'ì›…ë©ì´', 'ë¬¼ê³ ì¸ ê³³']:
                errors.append(f"Line {i+1}: puddleì˜ í•œê¸€ ëœ» '{ko_word}'ê°€ ë¶€ì ì ˆí•¨. ì˜¬ë°”ë¥¸ ëœ»: ë¬¼ì›…ë©ì´")
        
        # darn it íŠ¹ë³„ ê²€ì¦
        if en_word == 'darn it':
            if 'ì  ì¥' not in ko_word and 'ì´ëŸ°' not in ko_word:
                errors.append(f"Line {i+1}: darn itì˜ í•œê¸€ ëœ» '{ko_word}'ê°€ ë¶€ì ì ˆí•¨. ì˜¬ë°”ë¥¸ ëœ»: ì•„,ì´ëŸ°!, ì  ì¥")
        
        # ì—°ì†ëœ ê³µë°± í™•ì¸
        if '  ' in ko_word or '  ' in en_word:
            errors.append(f"Line {i+1}: ì—°ì†ëœ ê³µë°± ë°œê²¬")
    
    return errors

def check_duplicates(data):
    """ì¤‘ë³µ ë‹¨ì–´ í™•ì¸"""
    errors = []
    seen_words = set()
    
    for i, word in enumerate(data):
        word_key = f"{word['en']}|{word['ko']}"
        if word_key in seen_words:
            errors.append(f"Line {i+1}: ì¤‘ë³µ ë‹¨ì–´ ë°œê²¬: {word['en']} - {word['ko']}")
        seen_words.add(word_key)
    
    return errors

def enhanced_validate_unit_data(file_path):
    """ê°•í™”ëœ Unit ë°ì´í„° ê²€ì¦"""
    print(f"ğŸ” {file_path} ê°•í™” ê²€ì¦ ì‹œì‘...")
    print("=" * 50)
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSON í˜•ì‹ ì˜¤ë¥˜: {e}")
        return False
    
    errors = []
    
    # 1. ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
    print("ğŸ“‹ ê¸°ë³¸ êµ¬ì¡° ê²€ì¦ ì¤‘...")
    errors.extend(validate_basic_structure(data))
    
    # 2. ì¤‘ë³µ í™•ì¸
    print("ğŸ”„ ì¤‘ë³µ ë‹¨ì–´ í™•ì¸ ì¤‘...")
    errors.extend(check_duplicates(data))
    
    # 3. ì˜ë¯¸ ì¼ì¹˜ì„± ê²€ì¦
    print("ğŸ¯ ì˜ë¯¸ ì¼ì¹˜ì„± ê²€ì¦ ì¤‘...")
    errors.extend(validate_word_meaning_consistency(data))
    
    # 4. í’ˆì‚¬ ì¼ì¹˜ì„± ê²€ì¦
    print("ğŸ“ í’ˆì‚¬ ì¼ì¹˜ì„± ê²€ì¦ ì¤‘...")
    errors.extend(validate_pos_consistency(data))
    
    # 5. íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ê²€ì¦
    print("âš ï¸ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ê²€ì¦ ì¤‘...")
    errors.extend(validate_special_cases(data))
    
    # ê²°ê³¼ ì¶œë ¥
    print("=" * 50)
    print(f"ğŸ“Š ê²€ì¦ ê²°ê³¼:")
    print(f"   - ì´ ë‹¨ì–´ ìˆ˜: {len(data)}ê°œ")
    print(f"   - ì˜¤ë¥˜ ìˆ˜: {len(errors)}ê°œ")
    
    if errors:
        print(f"âŒ {len(errors)}ê°œì˜ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
        for i, error in enumerate(errors, 1):
            print(f"   {i}. {error}")
        print("\nğŸ”§ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ê²€ì¦í•´ì£¼ì„¸ìš”.")
        return False
    else:
        print("ğŸ‰ ëª¨ë“  ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        return True

def main():
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python enhanced_validator.py <unit_json_file>")
        print("ì˜ˆì‹œ: python enhanced_validator.py data/unit11.json")
        sys.exit(1)
    
    file_path = sys.argv[1]
    
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
        sys.exit(1)
    
    success = enhanced_validate_unit_data(file_path)
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
